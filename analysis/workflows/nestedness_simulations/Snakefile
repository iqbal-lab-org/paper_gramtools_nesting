import os
from pathlib import Path

configfile: "analysis/configs/common.yaml"
configfile: "analysis/configs/nestedness_simulations/nestedness_simulations.yaml"
container : config["container"]

include: "utils.py"
include: "../common_utils.py"

GMTOOLS_COMMIT = get_gmtools_commit()

#_____Set up output paths______#
output_base = Path(f"analysis/outputs/nestedness_simulations")
output_paths = output_base / "paths"
output_reads = output_base / "reads"

output_base_commit = output_base / GMTOOLS_COMMIT
output_build = output_base_commit / "gram_build"
output_gtyping = output_base_commit / "genotyping"
output_eval = output_base_commit / "evaluation"
output_plots = output_base_commit / "plots"

for variable in filter(lambda name: name.startswith("output"), dir()):
	Path(eval(variable)).mkdir(exist_ok=True, parents=True)


rule all:
		input:
			f'{output_plots}/{GMTOOLS_COMMIT}/precision_recall.pdf'

rule gram_build:
	input:
		get_data_path # function, in utils.py
	output:
		f'{output_build}/{{dataset}}_{{nesting}}/prg'
	params:
		gram_dir=directory(f'{output_build}/{{dataset}}_{{nesting}}'),
	resources:
		mem_mb=10000
	shell:
		f'gramtools build --gram_dir {{params.gram_dir}} --ref {config["fasta_ref"]} --prg {{input}} --kmer_size {config["k"]} --force'


rule simulate_paths:
	input:
		expand(f'{output_build}/{{dataset}}_{{nesting}}/prg',nesting=conditions,allow_missing=True)
	output:
		expand(f'{output_paths}/{{dataset}}_{{nesting}}.json',nesting=conditions,allow_missing=True),
		simu_fasta=f'{output_paths}/{{dataset}}_nonested.fasta',
	params:
		sample_ids=expand('{dataset}_{nesting}',nesting=conditions,allow_missing=True),
		output_dir=output_paths,
		num_paths=config["num_simu_paths"],
		paths_dir=f'{output_paths}/all_paths'
	shell:
		# The `mv`s are because we want the JSON sample names to only have dataset in name, but the filenames to also have the nesting condition
		"gramtools simulate --prg {input[0]} -o {params.output_dir} --sample_id {wildcards.dataset} -n {params.num_paths} --force;"
		"mv {params.output_dir}/{wildcards.dataset}.json {params.output_dir}/{params.sample_ids[0]}.json;"
		"mv {params.output_dir}/{wildcards.dataset}.fasta {params.output_dir}/{params.sample_ids[0]}.fasta;"
		"gramtools simulate --prg {input[1]} -o {params.output_dir} --sample_id {wildcards.dataset} -i {output.simu_fasta} --force;"
		"mv {params.output_dir}/{wildcards.dataset}.json {params.output_dir}/{params.sample_ids[1]}.json;"


checkpoint split_multifasta_paths:
	input:
		expand(f'{output_paths}/{{dataset}}_nonested.fasta', dataset = datasets)
	output:
		paths_dir=directory(f'{output_paths}/all_paths')
	shell:
		"""
		paths_dir={output.paths_dir}
		mkdir -p $paths_dir
		for fname in {input}; do
			dataset=$(basename $fname)
			dataset=${{dataset%.*}}
			dataset=${{dataset/_nonested/}}
			awk '/^>/{{s=\"'$paths_dir'/'$dataset'_\"++d\".fa\"}} {{print > s}}' $fname
		done
		"""
		# Latter line puts each record in its own numbered fasta

rule simulate_reads:
	input:
		f'{output_paths}/all_paths/{{dataset}}_{{num}}.fa'
	output:
		f'{output_reads}/{{dataset}}/e{{err}}_c{{cov}}/{{num}}.fq'

	params:
		output_dir=f'{output_reads}/{{dataset}}/e{{err}}_c{{cov}}',
		read_len=config["read_len"]
	shell:
		"mkdir -p {params.output_dir};"
		"art_illumina -ss HS25 -i {input} -l {params.read_len} -f {wildcards.cov} -qs {wildcards.err} -o {params.output_dir}/{wildcards.num};"
		"rm {params.output_dir}/{wildcards.num}.aln"


rule genotype:
	input:
		f'{output_reads}/{{dataset}}/e{{err}}_c{{cov}}/{{num}}.fq'
	output:
		f'{output_gtyping}/{{dataset}}/e{{err}}_c{{cov}}/{{nesting}}/{{num}}_genotyped.json'
	params:
		build_dir=f'{output_build}/k{config["k"]}_{{dataset}}_{{nesting}}',
		output_dir=f'{output_gtyping}/{{dataset}}/e{{err}}_c{{cov}}/{{nesting}}/{{num}}',
		read_stats_output=f'{output_gtyping}/{{dataset}}/e{{err}}_c{{cov}}/{{nesting}}/{{num}}_readstats.json',
	threads: 10
	resources:
		mem_mb=10000
	shell:
		"mkdir -p {params.output_dir};"
		"gramtools genotype -i {params.build_dir} -o {params.output_dir}"
		" --reads {input} --sample_id {wildcards.dataset}{wildcards.num} --ploidy haploid --force;"
		"cp {params.output_dir}/genotype/genotyped.json {output}; cp {params.output_dir}/read_stats.json {params.read_stats_output};"
		"rm -r {params.output_dir};"

rule evaluate:
	input:
		res_json=f'{output_gtyping}/{{dataset}}/e{{err}}_c{{cov}}/{{nesting}}/{{num}}_genotyped.json',
		truth_json=f'{output_paths}/{{dataset}}_{{nesting}}.json',
	output:
		f'{output_eval}/{{dataset}}/e{{err}}_c{{cov}}/{{nesting}}/{{num}}_eval.tsv'
	params:
		eval_script=f'{config["scripts"]}/nocond_simulations/evaluate.py'
	shell:
		'python3 {params.eval_script} -n {wildcards.dataset} --num {wildcards.num} '
		'-e {wildcards.err} -c {wildcards.cov} --nesting {wildcards.nesting} {input.truth_json} {input.res_json} {output} '

def aggregate_simu_paths(wildcards):
	checkpoint_output = checkpoints.split_multifasta_paths.get(**wildcards).output.paths_dir
	res = expand(f'{output_eval}/{{dataset}}/e{{err}}_c{{cov}}/{{nesting}}/{{num}}_eval.tsv', 
			dataset = datasets,
			err = config["simu_read_params"]["err_scaling"], cov = config["simu_read_params"]["fcov"],
			nesting = conditions,
			num = glob_wildcards(f'{checkpoint_output}/{{dataset}}_{{num}}.fa').num)
	#print(res)
	return res

rule aggregate:
	input:
		aggregate_simu_paths
	output:
		f'{output_eval}/all.tsv'
	params:
		eval_script=f'{config["scripts"]}/nocond_simulations/evaluate.py'
	shell:
		"python3 {params.eval_script} -p > {output};"	
		'cat {input} >> {output}'

rule plot:
	input:
		to_eval=rules.aggregate.output,
		nested_json=f'{output_paths}/{list(datasets)[0]}_nested.json'
	output:
		f'{output_plots}/precision_recall.pdf'
	params:
		plot_script=f'{config["scripts"]}/nestedness_simulations/plot.R',
		output_dir=f'{output_plots}'
	shell:
		"mkdir -p {params.output_dir} && Rscript {params.plot_script} {input.to_eval} {params.output_dir} {input.nested_json}"
