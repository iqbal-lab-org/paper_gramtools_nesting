"""
This workflow takes bed files listing regions + where they occur, a ref genome, a list of matched sample reads and pacbio assemblies and initial prgs to start from and runs:
	- validate input variant regions are present in truth assemblies
	- {vg, gramtools} prg index building
	- {vg, gramtools} mapping/genotyping
	- vcf merging per condition + validate input var regions present in called samples
	- edit distance of called regions to truth assemblies

The workflow has some rules similar/identical to pacb_ilmn_validation workflow, but is kept distinct as it does not assess gramtools perf against other standard var callers, but against other genome graph tool(s).
"""
WORKFLOW = 'tb_bigdel'
VALIDATION_WORKFLOW = 'pacb_ilmn_validation'

configfile: "analysis/configs/common.yaml"
configfile: f"analysis/configs/tb_bigdel.yaml"
#container: config["container"]

include: f"../{VALIDATION_WORKFLOW}/utils.py"
include: "../common_utils.py"

GMTOOLS_COMMIT = get_gmtools_commit()

#_____Set up output paths______#
output_gram_build = Path(f'{config["gram_builds_dir"]}/{WORKFLOW}/{GMTOOLS_COMMIT}')
output_vg_build = Path(f'{config["vg_builds_dir"]}/{WORKFLOW}')
output_base = Path(f'{config["output_dir"]}/{WORKFLOW}/')

output_bowtie_indexes = output_base / "bowtie_indexes"
output_regions = output_base / "input_regions"
output_minimap2 = output_regions / "minimap2"
output_genotyped = output_base / "genotyped"
output_prg_desc = output_base / "prg_descriptions"
output_alignments = output_base / "alignments"
output_gene_portions = output_alignments / "gene_portions"
output_plots = output_base / "plots"

conditions = [f"gramtools_{GMTOOLS_COMMIT}", "vg", "baseline_ref"]
output_gmtools = output_genotyped / conditions[0]
output_vg_mapped = output_genotyped / conditions[1] / "mapped_reads"
output_baseline_ref = output_genotyped / conditions[2]

mk_output_dirs(dir())

SAMPLES = get_samples(config["sample_tsv"])

localrules: all, baseline_ref_genotype

rule all:
	input:
		genotyped=expand(f'{output_genotyped}/{{condition}}_{{ftype}}', condition = conditions[0:2], ftype=["merged.vcf.gz", "validated.tsv"]),
		validated=f'{output_regions}/minimap2_validated.tsv',
		variant_counts=expand(f'{output_prg_desc}/{{condition}}_variants.tsv',condition = conditions[0:2]),
		stats=f'{output_plots}/stats.tsv'

rule index_pacb_assemblies:
	input:
		assembly=get_assembly
	output:
		expand(f'{output_bowtie_indexes}/{{sample}}.{{ext}}',ext=bowtie2_idx_extensions, allow_missing=True),
	shell:
		f"bowtie2-build {{input.assembly[0]}} {output_bowtie_indexes}/{{wildcards.sample}}"

rule minimap2_call:
	input:
		assembly=get_assembly,
		ref=config["starting_prg"]["fasta_ref"]
	output:
		gzipped=f'{output_minimap2}/{{sample}}_vars.vcf.gz',
		indexed=f'{output_minimap2}/{{sample}}_vars.vcf.gz.csi',
	params:
		vcf=f'{output_minimap2}/{{sample}}_vars.vcf',
	shell:
		"""
		minimap2 -c --cs {input.ref} {input.assembly} | sort -k6,6n -k8,8n | paftools.js call -l50 -L50 -f {input.ref} -s {wildcards.sample} - > {params.vcf}
		bgzip {params.vcf} && bcftools index {output.gzipped}
		"""

rule validate_input_regions:
	input:
		vcfs=expand(f'{output_minimap2}/{{sample}}_vars.vcf.gz',sample=SAMPLES),
		input_regions=config["beds"]["with_origin"],
	output:
		vcf=f'{output_regions}/minimap2_vars.vcf.gz',
		tsv=f'{output_regions}/minimap2_validated.tsv',
	params:
		validation_script=f'{config["scripts"]}/{WORKFLOW}/find_input_dels.py'
	shell:
		"""
		bcftools merge {input.vcfs} -Oz -o {output.vcf}
		python3 {params.validation_script} {output.vcf} {input.input_regions} {output.tsv}
		"""

rule gram_build:
	input:
		prg=config["starting_prg"]["gram_prg"],
		ref=config["starting_prg"]["fasta_ref"]
		
	output:
		f'{output_gram_build}/cov_graph',

	params:
		k=config["starting_prg"]["gram_kmer_size"],
		gram_dir=output_gram_build,

	resources:
		mem_mb=20000

	shell:
		"""
		gramtools build --prg {input.prg} --ref {input.ref} --kmer_size {params.k} --gram_dir {params.gram_dir} --force
		"""

rule vg_build:
	input:
		vg_graph=config["starting_prg"]["vg_prg"]
	output:
		xg=f'{output_vg_build / "prg.xg"}',
		gcsa=f'{output_vg_build / "prg.gcsa"}',
		snarls=f'{output_vg_build / "prg.snarls"}',
	params:
		k=config["starting_prg"]["vg_kmer_size"],
		X=config["starting_prg"]["vg_doubling_steps"],
	shadow:
		"shallow"
	resources:
		mem_mb=25000
	threads:
		10
	shell:
		"""
		vg index -k {params.k} -x {output.xg} -L {input.vg_graph} 
		vg prune -r -t {threads} {input.vg_graph} > pruned.vg
		vg index -L -X {params.X} -k {params.k} -g {output.gcsa} -p -t {threads} pruned.vg
		vg snarls {output.xg} > {output.snarls}
		#vg deconstruct -p ref -e {input.vg_graph} {input.vg_graph} > {{output.vcf}}
		"""

rule gramtools_genotype:
	input:
		gram_build_completed=rules.gram_build.output,
		gram_dir=f'{Path(rules.gram_build.output[0]).parent}',
		reads_files=get_reads

	output:
		sample_geno_dir=directory(f'{output_genotyped}/{conditions[0]}/{{sample}}'),
		gzipped=f'{output_genotyped}/{conditions[0]}/{{sample}}.vcf.gz',
		indexed=f'{output_genotyped}/{conditions[0]}/{{sample}}.vcf.gz.csi',
		jvcf=f'{output_genotyped}/{conditions[0]}/{{sample}}/genotype/genotyped.json',

	threads: 10
	resources:
		mem_mb=10000

	shell:
		"""
		gramtools genotype -i {input.gram_dir} -o {output.sample_geno_dir} --reads {input.reads_files} --sample_id {wildcards.sample} --max_threads {threads} --force
		cp {output.sample_geno_dir}/genotype/genotyped.vcf.gz {output.gzipped}
		bcftools index {output.gzipped}
		bcftools filter -i 'FT!="AMBIG"' {output.gzipped} -Oz -o tmp.vcf.gz
		mv tmp.vcf.gz {output.gzipped} && bcftools index {output.gzipped}
		"""

rule vg_map:
	input:
		xg=rules.vg_build.output.xg,
		gcsa=rules.vg_build.output.gcsa,
		reads_files=get_reads,
	output:
		mapped_packed=f'{output_vg_mapped}/mapped_{{sample}}.pack',
	params:
		mapped_gam=f'{output_vg_mapped}/mapped_{{sample}}.gam',
	threads: 10
	resources:
		mem_mb=10000
	shadow:
		"shallow"
	shell:
		"""
		rfilecmd=""
		for rfile in {input.reads_files}; do rfilecmd="$rfilecmd -f $rfile"; done
		vg map -x {input.xg} -g {input.gcsa} $rfilecmd -t {threads} > {params.mapped_gam}
		vg pack -x {input.xg} -g {params.mapped_gam} -Q 5 -o {output.mapped_packed}
		"""

rule vg_genotype:
	input:
		xg=rules.vg_build.output.xg,
		mapped=rules.vg_map.output.mapped_packed,
		snarls=rules.vg_build.output.snarls,
		vcf_to_genotype=config["vcf_to_genotype"]
	output:
		gzipped=f'{output_genotyped}/{conditions[1]}/{{sample}}.vcf.gz',
		indexed=f'{output_genotyped}/{conditions[1]}/{{sample}}.vcf.gz.csi',
	params:
		vcf=f'{output_genotyped}/{conditions[1]}/{{sample}}.vcf',
	shell:
		"""
		vg call {input.xg} -k {input.mapped} -v {input.vcf_to_genotype} -r {input.snarls} -s {wildcards.sample} --ploidy 1 > {params.vcf}
		bgzip {params.vcf} && bcftools index {output.gzipped}
		"""

rule baseline_ref_genotype:
	"""Dummy rule producing empty vcfs used for baseline gene portion-assembly alignments"""
	input:
		vcf=config["vcf_template"]
	output:
		gzipped=temp(f'{output_genotyped}/{conditions[2]}/{{sample}}.vcf.gz'),
		indexed=f'{output_genotyped}/{conditions[2]}/{{sample}}.vcf.gz.csi',
	params:
		vcf=f'{output_genotyped}/{conditions[2]}/{{sample}}.vcf',
	shell:
		"""
		cp {input.vcf} {params.vcf}
		sed -i 's/sample/{wildcards.sample}/' {params.vcf}
		bgzip {params.vcf} && bcftools index {output.gzipped}
		"""

rule merge_and_assess_vcfs:
	input:
		vcfs=expand(f'{output_genotyped}/{{condition}}/{{sample}}.vcf.gz', sample = SAMPLES, allow_missing=True),
		input_regions=config["beds"]["with_origin"],
	output:
		vcf=f'{output_genotyped}/{{condition}}_merged.vcf.gz',
		tsv=f'{output_genotyped}/{{condition}}_validated.tsv',
	params:
		validation_script=f'{config["scripts"]}/{WORKFLOW}/find_input_dels.py'
	shell:
		"bcftools merge {input.vcfs} -m all -Oz -o {output.vcf};"
		"python3 {params.validation_script} {output.vcf} {input.input_regions} {output.tsv}"


rule describe_vcf_prg:
	input:
		input_regions=config["beds"]["merged"],
		vg_vcf=f'{output_genotyped}/{conditions[1]}_merged.vcf.gz',
	output:
		desc=f'{output_prg_desc}/{conditions[1]}_variants.tsv',
	params:
		script=f'{config["scripts"]}/{WORKFLOW}/count_prg_variants.py',
	shell:
		"python3 {params.script} {input.vg_vcf} {input.input_regions} {output.desc}"	


rule describe_jvcf_prg:
	input:
		input_regions=config["beds"]["merged"],
		gram_jvcf=f'{output_genotyped}/{conditions[0]}/{SAMPLES[0]}/genotype/genotyped.json',
	output:
		desc=f'{output_prg_desc}/{conditions[0]}_variants.tsv',
	params:
		script=f'{config["scripts"]}/{WORKFLOW}/count_prg_variants.py',
	shell:
		"python3 {params.script} {input.gram_jvcf} {input.input_regions} {output.desc}"	


rule align_induced_gene_seqs_tb_bigdel:
	input:
		truth_ref_idx=expand(f'{output_bowtie_indexes}/{{sample}}.{{ext}}', ext=bowtie2_idx_extensions, allow_missing=True),
		result_vcf=f'{output_genotyped}/{{condition}}/{{sample}}.vcf.gz',
		var_regions=config["beds"]["with_flank"],
		fasta_ref=config["starting_prg"]["fasta_ref"],
	output:
		alignment_file=f'{output_alignments}/{{condition}}_{{sample}}.sam',
	params:
		gene_portions=f'{output_gene_portions}/{{condition}}_{{sample}}.fa',
		idx_prefix=f'{output_bowtie_indexes}/{{sample}}',
	resources:
		mem_mb=2000
	shell:
		"""
		> {params.gene_portions}
		IFS="\n"; for gene_line in $(cat {input.var_regions})
		do
			IFS="\t"; elems=($gene_line)	
			adjusted_start=$((${{elems[1]}} + 1))
			reg="${{elems[0]}}:${{adjusted_start}}-${{elems[2]}}"
			gene_name=${{elems[3]}}
			samtools faidx {input.fasta_ref} $reg | bcftools consensus -s {wildcards.sample} {input.result_vcf} |
				sed 's/>.*/>'${{gene_name}}'/' >> {params.gene_portions}
		done
		bowtie2 -x {params.idx_prefix} -U {params.gene_portions} -f > {output.alignment_file}
		"""

rule process_alignments:
	input:
		alignments=expand(f'{output_alignments}/{{condition}}_{{sample}}.sam', condition=conditions, sample=SAMPLES),
		var_regions=config["beds"]["with_flank"],
	output:
		stats=f'{output_plots}/stats.tsv'
	shell:
		f"""
		python3 {config["scripts"]}/{VALIDATION_WORKFLOW}/process_alignments.py {{input.alignments}} {{input.var_regions}} {output_plots}
		"""
