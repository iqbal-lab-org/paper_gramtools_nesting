"""
The workflow has some rules similar/identical to pacb_ilmn_validation workflow, but is kept distinct as it does not assess gramtools perf against other standard var callers, but against genome graph tool(s).
"""
WORKFLOW = 'tb_bigdel'

configfile: "analysis/configs/common.yaml"
configfile: f"analysis/configs/tb_bigdel.yaml"
#container: config["container"]

include: "../pacb_ilmn_validation/utils.py"
include: "../common_utils.py"

GMTOOLS_COMMIT = get_gmtools_commit()

#_____Set up output paths______#
output_gram_build = Path(f'{config["gram_builds_dir"]}/{WORKFLOW}/{GMTOOLS_COMMIT}')
output_vg_build = Path(f'{config["vg_builds_dir"]}/{WORKFLOW}')
output_base = Path(f'{config["output_dir"]}/{WORKFLOW}/')
output_base_commit = output_base / GMTOOLS_COMMIT
output_mapped = output_base_commit / "mapped_reads"

vcf_outputs_dirs = ["gramtools_genotype", "vg_genotype"]
output_gramtools_genotype = output_base_commit / vcf_outputs_dirs[0]
output_vg_genotype = output_base_commit / vcf_outputs_dirs[1]

mk_output_dirs(dir())

SAMPLES = get_samples(config["sample_tsv"])

rule all:
	input:
		expand(f'{output_base_commit}/{{condition}}_merged.vcf.gz', condition = vcf_outputs_dirs)

rule gram_build:
	input:
		prg=config["starting_prg"]["gram_prg"],
		ref=config["starting_prg"]["fasta_ref"]
		
	output:
		f'{output_gram_build}/cov_graph',

	params:
		k=config["starting_prg"]["gram_kmer_size"],
		gram_dir=output_gram_build,

	resources:
		mem_mb=20000

	shell:
		"""
		gramtools build --prg {input.prg} --ref {input.ref} --kmer_size {params.k} --gram_dir {params.gram_dir} --force
		"""

rule vg_build:
	input:
		vg_graph=config["starting_prg"]["vg_prg"]
	output:
		xg=f'{output_vg_build / "prg.xg"}',
		gcsa=f'{output_vg_build / "prg.gcsa"}',
		snarls=f'{output_vg_build / "prg.snarls"}',
	params:
		k=config["starting_prg"]["vg_kmer_size"],
	shadow:
		"shallow"
	resources:
		mem_mb=25000
	threads:
		10
	shell:
		"""
		vg index -k {params.k} -x {output.xg} -L {input.vg_graph} 
		vg prune -r -t {threads} {input.vg_graph} > pruned.vg
		vg index -L -X 3 -k {params.k} -g {output.gcsa} -p -t {threads} pruned.vg
		vg snarls {output.xg} > {output.snarls}
		#vg deconstruct -p ref -e {input.vg_graph} {input.vg_graph} > {{output.vcf}}
		"""

rule gramtools_genotype:
	input:
		gram_build_completed=rules.gram_build.output,
		gram_dir=f'{Path(rules.gram_build.output[0]).parent}',
		reads_files=get_reads

	output:
		sample_geno_dir=directory(f'{output_gramtools_genotype}/{{sample}}'),
		out_vcf=f'{output_base_commit}/{vcf_outputs_dirs[0]}/{{sample}}.vcf.gz',
		bcftools_index=f'{output_gramtools_genotype}/{{sample}}.vcf.gz.csi',

	threads: 10
	resources:
		mem_mb=10000

	shell:
		"""
		gramtools genotype -i {input.gram_dir} -o {output.sample_geno_dir} --reads {input.reads_files} --sample_id {wildcards.sample} --max_threads {threads} --force
		cp {output.sample_geno_dir}/genotype/genotyped.vcf.gz {output.out_vcf}
		bcftools index {output.out_vcf}
		"""

rule vg_map:
	input:
		xg=rules.vg_build.output.xg,
		gcsa=rules.vg_build.output.gcsa,
		reads_files=get_reads,
	output:
		mapped_packed=f'{output_mapped}/mapped_{{sample}}.pack',
	params:
		mapped_gam=f'{output_mapped}/mapped_{{sample}}.gam',
	threads: 10
	resources:
		mem_mb=10000
	shadow:
		"shallow"
	shell:
		"""
		rfilecmd=""
		for rfile in {input.reads_files}; do rfilecmd="$rfilecmd -f $rfile"; done
		vg map -x {input.xg} -g {input.gcsa} $rfilecmd -t {threads} > {params.mapped_gam}
		vg pack -x {input.xg} -g {params.mapped_gam} -Q 5 -o {output.mapped_packed}
		"""

rule vg_genotype:
	input:
		xg=rules.vg_build.output.xg,
		mapped=rules.vg_map.output.mapped_packed,
		snarls=rules.vg_build.output.snarls,
		vcf_to_genotype=config["vg_vcf_to_genotype"]
	output:
		gzipped=f'{output_base_commit}/{vcf_outputs_dirs[1]}/{{sample}}.vcf.gz',
		indexed=f'{output_vg_genotype}/{{sample}}.vcf.gz.csi',
	params:
		vcf=f'{output_vg_genotype}/{{sample}}.vcf',
	shell:
		"""
		vg call {input.xg} -k {input.mapped} -v {input.vcf_to_genotype} -r {input.snarls} -s {wildcards.sample} --ploidy 1 > {params.vcf}
		bgzip {params.vcf} && bcftools index {output.gzipped}
		"""

rule merge_vcfs:
	input:
		vcfs=expand(f'{output_base_commit}/{{condition}}/{{sample}}.vcf.gz', sample = SAMPLES, allow_missing=True),
	output:
		f'{output_base_commit}/{{condition}}_merged.vcf.gz'
	shell:
		"bcftools merge {input.vcfs} -m all -Oz -o {output}"
